{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# S1: MCMTpy Notebook\n",
    "\n",
    "In this notebook, we will show some of the key steps in **MCMTpy** for **Focal Mechanism Inversion**, including **DC** (double couple) and **MT** (moment tensor) inversion (not in now). \n",
    "\n",
    "The steps to do inversion process are:    \n",
    "* Compute Green Function Database\n",
    "* Synthesize the Test Data\n",
    "* Prepare Data for MCMTpy\n",
    "* Inversion of DC\n",
    "* Inversion of MT\n",
    "* Result Visualization\n",
    "\n",
    "\n",
    "More details on the descriptions of data processing, parameters can be found in the online [documentations](https://github.com/OUCyf) and our paper.\n",
    "\n",
    "`MCMTpy: A Python Package for Simultaneous Inversion of Source Location, Focal Mechanism, and Rupture Directivity. In prep for Seismological Research Letter.`\n",
    "\n",
    "\n",
    "\n",
    "Fu Yin\n",
    "\n",
    "School of Earth and Space Sciences\n",
    "\n",
    "University of Science and Technology of China\n",
    "\n",
    "No.96, JinZhai Road Baohe District, Hefei, Anhui, 230026, P.R.China.\n",
    "\n",
    "June 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building env for MCMTpy\n",
    "\n",
    "Before running this notebook, make sure that you have created and activated the conda env made for MCMTpy. If not, you can create one using command lines below (note that jupyter is installed with the command lines here in order to run this notebook). \n",
    "\n",
    "```bash\n",
    "$ conda create -n MCMTpy  python=3.8 numpy=1.16 matplotlib=3.1.1 mpi4py obspy pyasdf json5 tqdm\n",
    "$ conda activate MCMTpy\n",
    "$ pip install pyfk\n",
    "$ pip install MCMTpy\n",
    "```\n",
    "\n",
    "Then you need to activate this notebook with the newly built MCMTpy env by invoking the jupyter with the following command line.\n",
    "\n",
    "```bash\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "Now we can begin to load the modules needed for this practise. \n",
    "\n",
    "- First, let's run the cell below to import packages and the last cell with [helper functions](#helper).\n",
    "- Back from Helper Function\n",
    "<a id='helper_back'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import obspy\n",
    "import json5\n",
    "import pyasdf\n",
    "import shutil\n",
    "# import pygmt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import Stream\n",
    "from obspy.taup import TauPyModel\n",
    "from IPython.display import Image\n",
    "from MCMTpy.utils.asdf_function import get_StationXML,Add_waveforms_head_info\n",
    "from MCMTpy.utils.asdf_function import Add_waveforms,Add_stationxml,get_QuakeML,Add_quakeml\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup Green Function Database\n",
    "\n",
    "- The first step of **MCMTpy** is to build Green's function database. All parameters are written into a JSON file named **build_GFs.json**. Some brief descriptions of the parameters are included here following the definination, but note that more details on this can be found in documentations. \n",
    "\n",
    "- We do not recommend using relative paths because of the possibility of errors. Absolute paths are preferred."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The root directory of the project\n",
    "example_path = '/Users/yf/3.Project/8.MCMTpy/MCMTpy-master/data/example_yunnan'\n",
    "\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "# we expect no parameters need to be changed below\n",
    "#------------------------------------------------------------#\n",
    "# 1. get notebook path\n",
    "notebook_path = sys.path[0]\n",
    "os.chdir(notebook_path)\n",
    "\n",
    "# 2. change path to Green_Funcs\n",
    "os.chdir('../Green_Funcs')\n",
    "print(os.listdir())\n",
    "\n",
    "# 3. show build_GFs.json \n",
    "filename = 'build_GFs.json'\n",
    "with open(filename, 'r',encoding='utf-8') as f1:\n",
    "    gfs_json=json5.load(f1)\n",
    "f1.close()\n",
    "\n",
    "# 4. change parameters with absolute path\n",
    "gfs_json['Source_Station_info'] = os.path.join(example_path,\"Green_Funcs/Source_Station_info.txt\")\n",
    "gfs_json[\"DATADIR\"] = os.path.join(example_path,\"Green_Funcs/GFs\")\n",
    "gfs_json[\"DATADIR_splits\"] = os.path.join(example_path,\"Green_Funcs/GFs/GFs_splits\")\n",
    "gfs_json[\"Velocity_model\"] =  os.path.join(example_path,\"v_model/v_model_yunnan.txt\")        \n",
    "gfs_json_new = os.path.join(example_path,'Green_Funcs/build_GFs_new.json')\n",
    "\n",
    "with open(gfs_json_new,'w') as f2:\n",
    "    json5.dump(gfs_json, f2, indent=2)\n",
    "f2.close()\n",
    "\n",
    "gfs_json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NOTE**: if you want to make any changes of parameters to the json-file, please open it with a text editor and make the changes manually. It is strongly recommended to use a separate directory apart from the $notebook_path as the **GF databases can become very large**, depending on the different problem! For real examples, the GF databases may require up to several GBs of free disc space. For quick calculations, we use **'Database_mode': False**. Now we will setup GFs datebase!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# run MCMTpy in shell\n",
    "# NOTE: too long running time，please comment out!\n",
    "# !mpirun -n 4 MCMTpy build_GFs pyfk -c build_GFs_new.json  > gfs.log\n",
    "\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../Green_Funcs/GFs')\n",
    "print(os.listdir())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['.DS_Store', 'GFs_splits', 'prepro_para_info.txt', 'write_Source_Station_info_MPI.txt']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- MCMTpy will generates 2 logging files when it builds GFs datebase, that is **prepro_para_info.txt** and **write_Source_Station_info_MPI**. They record all the parameter information of GFs datebase."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MCMTpy generate 2 logging file\n",
    "\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../Green_Funcs/GFs')\n",
    "print('************************************')\n",
    "print('prepro_para_info.txt:\\n\\n')\n",
    "!cat prepro_para_info.txt\n",
    "\n",
    "print('\\n\\n\\n************************************')\n",
    "print('write_Source_Station_info_MPI.txt:\\n\\n\\n')\n",
    "# !cat write_Source_Station_info_MPI.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Syn the Test Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The synthesized test data can help us check whether the Green's function database is correctly calculated."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change path to Green_Funcs\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../syn')\n",
    "print(os.listdir())\n",
    "\n",
    "\n",
    "# show build_GFs.json \n",
    "filename = 'syn.json'\n",
    "with open(filename, 'r',encoding='utf-8') as f1:\n",
    "    syn_json=json5.load(f1)\n",
    "\n",
    "\n",
    "# change parameters with absolute path\n",
    "syn_json[\"GFs_json_file\"] = os.path.join(example_path,\"Green_Funcs/build_GFs_new.json\")\n",
    "syn_json[\"Stf_file\"] = os.path.join(example_path,\"syn/Stf_file/Stf_file.sac\")\n",
    "syn_json[\"Output_path\"] = os.path.join(example_path,\"syn/Synthetic\")       \n",
    "syn_json_new = os.path.join(example_path,'syn/syn_new.json')\n",
    "\n",
    "with open(syn_json_new,'w') as f2:\n",
    "    json5.dump(syn_json, f2, indent=2)\n",
    "f2.close()\n",
    "\n",
    "syn_json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now we will syn test data in datebase:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# run MCMTpy in shell\n",
    "\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../syn')\n",
    "\n",
    "shutil.rmtree('./Synthetic')\n",
    "!MCMTpy syn pyfk  -c ./syn_new.json  > syn.log"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Read data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "## change the path\n",
    "h5_path = os.path.join(example_path,'syn/Synthetic/SYN_test.h5')\n",
    "source_name = 'source_syn'\n",
    "\n",
    "\n",
    "### read h5 data --> Sta_data (dict)\n",
    "ds_raw=pyasdf.ASDFDataSet(h5_path,mpi=False,mode='r')                           \n",
    "Station_list = ds_raw.waveforms.list()\n",
    "Station_num = len(Station_list)\n",
    "\n",
    "Sta_data={}                        \n",
    "for i in range(0,Station_num,1):\n",
    "    info={}\n",
    "    tags = ds_raw.waveforms[Station_list[i]].get_waveform_tags()\n",
    "    if source_name in tags:                                           \n",
    "        raw_sac = ds_raw.waveforms[Station_list[i]][source_name]\n",
    "        tp = float( ds_raw.waveforms[Station_list[i]][source_name][0].stats.asdf['labels'][1] ) \n",
    "        ts = float( ds_raw.waveforms[Station_list[i]][source_name][0].stats.asdf['labels'][3] ) \n",
    "        info.update({ \"tp\": tp})  \n",
    "        info.update({ \"ts\": ts})\n",
    "        info.update({ \"data\": raw_sac})\n",
    "        Sta_data.update({ Station_list[i]: info})\n",
    "\n",
    "# Sta_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- View syn waveform:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot data\n",
    "ax = Sta_data['YN.YUM']['data'].plot()\n",
    "Sta_data['YN.YUM']['data'][0].stats\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prepare data for MCMTpy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- View the station distribution："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# data path\n",
    "allfiles_path = os.path.join(example_path,'YN.202105212148_Inv/YN.202105212148_raw/*.SAC')  \n",
    "\n",
    "# stations with amplitude exceeds the range\n",
    "limiting_sta = ['XG.CHT','XG.HDQ','XG.XBT','XG.ZYT','YN.TUS','YN.YUX']         \n",
    "\n",
    "# 1. read raw data\n",
    "data = read_data(allfiles_path)\n",
    "\n",
    "# 2. pygmt plot\n",
    "# fig = plot_station(data,limiting_sta)\n",
    "# fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Ray tracing:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3. taup ray tracing\n",
    "model_path = os.path.join(example_path,\"v_model/v_model.npz\")\n",
    "\n",
    "# model can also be \"iasp91\" or \"prem\"\n",
    "model = TauPyModel(model=model_path)\n",
    "for i in range(0,len(data),1):\n",
    "    depth = data[i].stats.sac['evdp']\n",
    "    distance = data[i].stats.sac['dist']\n",
    "    ray_p,tp,angle_p,ray_s,ts,angle_s = get_taup_tp_ts(model,depth,distance,degree=False)\n",
    "    data[i].stats.sac[\"t1\"]=tp                  \n",
    "    data[i].stats.sac[\"t2\"]=ts\n",
    "\n",
    "    \n",
    "# 4. plot raypath of the last station\n",
    "path_p = model.get_ray_paths(source_depth_in_km=depth,\n",
    "                             distance_in_degree=distance/111.19,\n",
    "                             phase_list=[\"p\", \"P\",\"s\", \"S\"])\n",
    "path_p[0].path.dtype\n",
    "ax = path_p.plot_rays(plot_type=\"cartesian\",legend=True)                    # 'spherical'  'cartesian'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Before data preprocessing:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# last station waveform\n",
    "ax = data[-3:].plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Data preprocessing："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "freqmin       = 0.005              # pre filtering frequency bandwidth (hz)\n",
    "freqmax       = 2                  # note this cannot exceed Nquist frequency (hz)\n",
    "samp_freq     = 5                  # targeted sampling rate (hz)\n",
    "p_n0          = 50                 # number of sampling points before P wave arrives\n",
    "npts          = 2048               # data length\n",
    "\n",
    "\n",
    "# 5. 数据预处理\n",
    "preprocess(data,freqmin,freqmax,samp_freq,p_n0,npts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- After data preprocessing："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# last station waveform\n",
    "ax = data[-3:].plot()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Output ASDF and SAC data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# output data/file path\n",
    "Output_path   = os.path.join(example_path,\"YN.202105212148_Inv/YN.202105212148_MCMTpy\")                                  # 输出文件存放的位置\n",
    "source_name   = \"source_enz\"                                                    # asdf‘s source_tag\n",
    "ASDF_filename = \"YN.202105212148\"                                               # asdf filename\n",
    "\n",
    "# 6. output ASDF and SAC data\n",
    "shutil.rmtree(Output_path)\n",
    "os.mkdir(Output_path)\n",
    "write_ASDF(data,Output_path,source_name,ASDF_filename)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Inv of DC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Change inversion parameters:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change path to Green_Funcs\n",
    "os.chdir(notebook_path)\n",
    "\n",
    "# plot alpha\n",
    "N=5e3\n",
    "a=1000                  # 0.2*N\n",
    "b=100                   # 0.04*N\n",
    "alpha_max=100\n",
    "alpha_min=0\n",
    "\n",
    "tt=np.linspace(0, round(N), num=round(N))\n",
    "yy=np.zeros(len(tt))\n",
    "for i in range(0,len(tt)):\n",
    "    yy[i]=(alpha_max-alpha_min)*(a+math.exp((tt[0]-a)/b))/(a+math.exp((tt[i]-a)/b))+alpha_min\n",
    "    \n",
    "fig, axs = plt.subplots(1,1)\n",
    "axs.plot(tt,yy, linestyle='-', color='red', lw=3, alpha=0.6)\n",
    "axs.set_xlabel(\"Sample Number\",fontsize=17)\n",
    "axs.set_ylabel(\"Alpha Value\",fontsize=17)\n",
    "\n",
    "# save figure\n",
    "figurename=os.path.join('./S1_figure/Alpha.png')\n",
    "plt.savefig(figurename,dpi=800, format=\"png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# change path to Green_Funcs\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../YN.202105212148_Inv/dc_inv')\n",
    "print(os.listdir())\n",
    "\n",
    "\n",
    "# show build_GFs.json \n",
    "filename = 'sample_dc.json'\n",
    "with open(filename, 'r',encoding='utf-8') as f1:\n",
    "    sample_dc_json=json5.load(f1)\n",
    "\n",
    "\n",
    "# change parameters with absolute path\n",
    "sample_dc_json[\"GFs_json_file\"] = os.path.join(example_path,\"Green_Funcs/build_GFs_new.json\")\n",
    "sample_dc_json[\"GFs_file\"] =os.path.join(example_path,\"Green_Funcs/GFs/GFs_splits\" )          \n",
    "sample_dc_json[\"Raw_data_file\"] = os.path.join(example_path,\"YN.202105212148_Inv/YN.202105212148_MCMTpy/YN.202105212148.h5\")              \n",
    "sample_dc_json[\"Output_path\"] = os.path.join(example_path,\"YN.202105212148_Inv/dc_inv/Output_YN.202105212148_dc\")         \n",
    "sample_dc_json[\"Raw_data_inv_info\"] = os.path.join(example_path,\"YN.202105212148_Inv/dc_inv/Raw_data_inv_info.txt\")     \n",
    "sample_dc_json[\"Raw_data_inv_info_writed\"] = os.path.join(example_path,\"YN.202105212148_Inv/dc_inv/Raw_data_inv_info_writed.txt\") \n",
    "sample_dc_json_new = os.path.join(example_path,'YN.202105212148_Inv/dc_inv/sample_dc_new.json')\n",
    "\n",
    "sample_dc_json[\"MPI_n\"] = 4                         # CPU num\n",
    "sample_dc_json[\"Chains_n\"] = 4                      # Eack MK-chains num\n",
    "sample_dc_json[\"N\"] = 1e1                           # each chain‘s search number\n",
    "\n",
    "sample_dc_json[\"alpha_max\"] = 100                   # The initial value of alpha\n",
    "sample_dc_json[\"alpha_min\"] = 0                     # The final value of alpha\n",
    "sample_dc_json[\"a\"] = 10                     \n",
    "sample_dc_json[\"b\"] = 10               \n",
    "\n",
    "with open(sample_dc_json_new,'w') as f2:\n",
    "    json5.dump(sample_dc_json, f2, indent=2)\n",
    "f2.close()\n",
    "\n",
    "# sample_dc_json"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['plot.log', '.DS_Store', 'figure_dc', 'sample_dc_new.json', 'Output_YN.202105212148_dc', 'sample.log', 'sample_dc.json', 'plot_dc.json', 'plot_dc_new.json', 'Raw_data_inv_info.txt']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now run MCMTpy:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# run MCMTpy in shell\n",
    "\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../YN.202105212148_Inv/dc_inv')\n",
    "# !MCMTpy  sample MH  -c ./sample_dc_new.json #> sample.log"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Plot Results of DC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Change plotting parameters:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# change path to Green_Funcs\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../YN.202105212148_Inv/dc_inv')\n",
    "print(os.listdir())\n",
    "\n",
    "\n",
    "# read plot_dc.json \n",
    "filename = 'plot_dc.json'\n",
    "with open(filename, 'r',encoding='utf-8') as f1:\n",
    "    plot_dc_json=json5.load(f1)\n",
    "\n",
    "\n",
    "# change parameters with absolute path\n",
    "plot_dc_json[\"plot_output_path\"] = os.path.join(example_path,\"YN.202105212148_Inv/dc_inv/figure_dc\")                                              \n",
    "plot_dc_json[\"Inv_json_file\"] = os.path.join(example_path,\"YN.202105212148_Inv/dc_inv/sample_dc_new.json\") \n",
    "plot_dc_json_new = os.path.join(example_path,'YN.202105212148_Inv/dc_inv/plot_dc_new.json')\n",
    "\n",
    "# 1.hist\n",
    "plot_dc_json[\"plot_hist\"] =True\n",
    "plot_dc_json[\"N_start\"] = 0 \n",
    "plot_dc_json[\"N_start_accept\"] = 1\n",
    "plot_dc_json[\"num_bins\"] =  50     \n",
    "plot_dc_json[\"num_std\"] =5      \n",
    "plot_dc_json[\"labels_name\"] = ['Mw','strike/°','dip/°','rake/°','z/km']\n",
    "\n",
    "# 2. misfit\n",
    "plot_dc_json[\"plot_misfit\"] = True\n",
    "plot_dc_json[\"MPI_n_st\"] = 0\n",
    "plot_dc_json[\"Chains_n_st\"] = 0\n",
    "\n",
    "# 3. waveform\n",
    "plot_dc_json[\"plot_waveform\"] = True\n",
    "plot_dc_json[\"FM_best\"] = [6.68,  135.1,  87.0,  -168.1,    25.58,  99.86,  5.95,  -0.57 ]     \n",
    "plot_dc_json[\"line_n_sta\"] = 3                                     # Draw the data of several stations in a row\n",
    "plot_dc_json[\"max_p_ylim\"] = 1                                     # max amp y-axis of p wave\n",
    "plot_dc_json[\"max_s_ylim\"] = 1.0\n",
    "plot_dc_json[\"max_surf_ylim\"] = 1\n",
    "plot_dc_json[\"plot_comp\"] = [[1,1,0],[0,0,0],[1,1,1]]              # What components do you want to draw? P、S、Surf's Z/R/T\n",
    "\n",
    "\n",
    "with open(plot_dc_json_new,'w') as f2:\n",
    "    json5.dump(plot_dc_json, f2, indent=2)\n",
    "f2.close()\n",
    "\n",
    "# plot_dc_json"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['plot.log', '.DS_Store', 'figure_dc', 'sample_dc_new.json', 'Output_YN.202105212148_dc', 'sample.log', 'sample_dc.json', 'plot_dc.json', 'plot_dc_new.json', 'Raw_data_inv_info.txt']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now run MCMTpy:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# run MCMTpy in shell\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('../YN.202105212148_Inv/dc_inv')\n",
    "!MCMTpy plot pyfk -c plot_dc_new.json > plot.log"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/yf/opt/anaconda3/lib/python3.8/site-packages/MCMTpy-0.1.0a1-py3.8.egg/MCMTpy/plotting/pyfk_plot/plot_misfit.py:51: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\r\n",
      "Invalid limit will be ignored.\r\n",
      "/Users/yf/opt/anaconda3/lib/python3.8/site-packages/MCMTpy-0.1.0a1-py3.8.egg/MCMTpy/plotting/pyfk_plot/plot_misfit.py:58: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\r\n",
      "Invalid limit will be ignored.\r\n",
      "/Users/yf/opt/anaconda3/lib/python3.8/site-packages/MCMTpy-0.1.0a1-py3.8.egg/MCMTpy/plotting/pyfk_plot/plot_misfit.py:68: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\r\n",
      "Invalid limit will be ignored.\r\n",
      "/Users/yf/opt/anaconda3/lib/python3.8/site-packages/MCMTpy-0.1.0a1-py3.8.egg/MCMTpy/plotting/pyfk_plot/plot_misfit.py:78: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\r\n",
      "Invalid limit will be ignored.\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Show figure of inversion:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show hist\n",
    "fig_hist = os.path.join(plot_dc_json[\"plot_output_path\"],'hist.jpg')\n",
    "Image(filename = fig_hist, width=600)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show hist_accept\n",
    "fig_hist_accept = os.path.join(plot_dc_json[\"plot_output_path\"],'hist_accept.jpg')\n",
    "Image(filename = fig_hist_accept, width=600)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show misfit\n",
    "fig_misfit = os.path.join(plot_dc_json[\"plot_output_path\"],'misfit.jpg')\n",
    "Image(filename = fig_misfit, width=600)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# show waveform\n",
    "fig_waveform = os.path.join(plot_dc_json[\"plot_output_path\"],'waveform.jpg')\n",
    "Image(filename = fig_waveform, width=1000)\n",
    "\n",
    "# annotation:\n",
    "# waveform = os.path.join(plot_dc_json[\"plot_output_path\"],'waveform.jpg')\n",
    "# fig_waveform = plt.imread(waveform)\n",
    "# plt.imshow(fig_waveform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![]('./figure_dc/hist.jpg')"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The end.\n",
    "\n",
    "We hope you enjoy it! \n",
    "\n",
    "Most of the core steps of MCMTpy are included here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Helper function：\n",
    "<a id='helper'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "#***************************************************************\n",
    "#*                       -----------\n",
    "#*                        Functions\n",
    "#*                       -----------\n",
    "#***************************************************************\n",
    "# The notobook needs some functions, please run it firstly:\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# 1.read raw data\n",
    "def read_data(allfiles_path):\n",
    "\n",
    "    allfiles = sorted( glob.glob(allfiles_path) )\n",
    "    data_raw = Stream()\n",
    "    for i in range(0,len(allfiles),1):\n",
    "        try:\n",
    "            tr = obspy.read(allfiles[i])\n",
    "            data_raw += tr\n",
    "        except Exception:\n",
    "            print(allfiles[i],': no such file or obspy read error');continue\n",
    "    data = data_raw.copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# 2.plot station\n",
    "def plot_station(data,limiting_sta):\n",
    "    lons = []; lats = []; net = []; sta = []; names = []\n",
    "    unique_stations = np.unique([tr.stats.station for tr in data])\n",
    "    for station in unique_stations:\n",
    "        tr = data.select(station=station)[0]\n",
    "        lons.append(tr.stats.sac.stlo)\n",
    "        lats.append(tr.stats.sac.stla)\n",
    "        net.append(tr.stats.network)\n",
    "        sta.append(tr.stats.station)\n",
    "        names.append(f'{tr.stats.network}.{tr.stats.station}')\n",
    "\n",
    "    region = [np.min(lons), np.max(lons), np.min(lats), np.max(lats)]\n",
    "    x_pad = (region[1] - region[0]) * 0.1\n",
    "    y_pad = (region[3] - region[2]) * 0.1\n",
    "    region = [region[0] - x_pad, region[1] + x_pad, region[2] - y_pad, region[3] + y_pad]\n",
    "\n",
    "    lon_0 = np.mean(region[:2])\n",
    "    lat_0 = np.mean(region[2:])\n",
    "    if lat_0 > 0:\n",
    "        ref_lat = 90\n",
    "    else:\n",
    "        ref_lat = -90\n",
    "    projection = f'S{lon_0}/{ref_lat}/6i'\n",
    "\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "\n",
    "    fig.coast(region=region, projection=projection,shorelines=True,water='lightblue',land='lightgrey',\n",
    "              N=[1, 2],frame='a')\n",
    "\n",
    "    focal_mechanism = dict(strike=141, dip=68, rake=-153, magnitude=5.2) \n",
    "\n",
    "    fig.meca(focal_mechanism, scale=\"0.5c\",longitude=tr.stats.sac.evlo,latitude=tr.stats.sac.evla,\n",
    "             depth=12.0,G='red')\n",
    "\n",
    "    for i in range(0,len(names),1):\n",
    "        if names[i] in limiting_sta:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'blue'\n",
    "        fig.plot(lons[i], lats[i],style='i0.1i',color=color,pen=True,label='Station') \n",
    "\n",
    "    fig.text(text=names,x=lons,y=lats,X ='0.2c',Y ='0.2c',font=\"5p,Helvetica-Bold,white\",\n",
    "             fill=\"orange\",transparency=20) \n",
    "\n",
    "    return fig\n",
    "    \n",
    "    \n",
    "\n",
    "#----------------------------------------------------#\n",
    "# 3.get_taup_tp_ts\n",
    "def get_taup_tp_ts(model,depth,distance,degree=None):\n",
    "    if degree==False:\n",
    "        distance = distance/111.19\n",
    "\n",
    "    time_p = model.get_travel_times(source_depth_in_km=depth,\n",
    "                                    distance_in_degree=distance,\n",
    "                                    phase_list=[\"p\", \"P\"])\n",
    "\n",
    "    time_s = model.get_travel_times(source_depth_in_km=depth,\n",
    "                                    distance_in_degree=distance,\n",
    "                                    phase_list=[\"s\", \"S\"])\n",
    "\n",
    "    ray_p = time_p[0].ray_param\n",
    "    tp = time_p[0].time\n",
    "    angle_p = time_p[0].incident_angle\n",
    "\n",
    "    ray_s = time_s[0].ray_param\n",
    "    ts = time_s[0].time\n",
    "    angle_s = time_s[0].incident_angle\n",
    "\n",
    "    return ray_p,tp,angle_p,ray_s,ts,angle_s\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# 4.preprocess\n",
    "def preprocess(data,freqmin,freqmax,samp_freq,p_n0,npts):\n",
    "\n",
    "    data.detrend(type='demean')\n",
    "    data.detrend(type='simple')\n",
    "    data.taper(max_percentage=0.05)\n",
    "\n",
    "    data.filter('bandpass', freqmin=freqmin, freqmax=freqmax, corners=4, zerophase=True)  # bandpass\n",
    "    data.resample(samp_freq,window='hanning',no_filter=True, strict_length=False)         # resample\n",
    "\n",
    "    for i in range(0,len(data),1):\n",
    "        b = data[i].stats.sac['b']\n",
    "        t1 = data[i].stats.sac['t1']\n",
    "        t_start = data[i].stats.starttime + (t1-b) - p_n0/samp_freq\n",
    "        t_end_npts = t_start+npts/samp_freq\n",
    "        t_endtime = data[i].stats.endtime\n",
    "        if t_end_npts > t_endtime:\n",
    "            t_end = t_endtime\n",
    "        else:\n",
    "            t_end = t_end_npts\n",
    "\n",
    "        data[i].trim(t_start, t_end)\n",
    "\n",
    "    for i in range(0,round(len(data)/3)):\n",
    "        t_start_1 = data[3*i].stats.starttime\n",
    "        t_start_2 = data[3*i+1].stats.starttime\n",
    "        t_start_3 = data[3*i+2].stats.starttime\n",
    "        t_end_1 = data[3*i].stats.endtime\n",
    "        t_end_2 = data[3*i+1].stats.endtime\n",
    "        t_end_3 = data[3*i+2].stats.endtime\n",
    "        t_start = max(t_start_1,t_start_2,t_start_3)\n",
    "        t_end = min(t_end_1,t_end_2,t_end_3)\n",
    "        data[3*i:3*i+3].trim(t_start, t_end)\n",
    "\n",
    "    # velocity(nm/s) to velocity(cm/s)\n",
    "    for i in range(0,len(data),1):\n",
    "        data[i].data = 1e-6*data[i].data\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# 5.write_ASDF\n",
    "def write_ASDF(data_enz,Output_path,source_name,ASDF_filename):\n",
    "    source_lat   = data_enz[0].stats.sac.evla\n",
    "    source_lon   = data_enz[0].stats.sac.evlo\n",
    "    source_depth = data_enz[0].stats.sac.evdp\n",
    "    source_time  = data_enz[0].stats.starttime + data_enz[0].stats.sac.b\n",
    "\n",
    "    Output_file_path = os.path.join(Output_path, ASDF_filename+'.h5')\n",
    "    catalog_create   = get_QuakeML(source_name, source_lat, source_lon, source_depth,source_time)\n",
    "    Add_quakeml(Output_file_path,catalog_create)\n",
    "\n",
    "    Station_num = round(len(data_enz)/3)\n",
    "    for i in range(0,Station_num,1): \n",
    "        net_sta_name     = data_enz[3*i].stats.network+'_'+data[3*i].stats.station\n",
    "        station_network  = data_enz[3*i].stats.network\n",
    "        station_name     = data_enz[3*i].stats.station\n",
    "        station_lat      = data_enz[3*i].stats.sac.stla\n",
    "        station_lon      = data_enz[3*i].stats.sac.stlo\n",
    "        station_depth    = 0\n",
    "        station_distance = data_enz[3*i].stats.sac.dist\n",
    "        station_az       = data_enz[3*i].stats.sac.az\n",
    "        station_baz      = data[3*i].stats.sac.baz\n",
    "        tp               = data_enz[3*i].stats.sac.t1\n",
    "        ts               = data_enz[3*i].stats.sac.t2\n",
    "        stream           = data_enz[3*i:3*i+3].copy()\n",
    "        starttime        = data_enz[3*i].stats.starttime\n",
    "        time_before_first_arrival = p_n0/samp_freq\n",
    "\n",
    "        inv=get_StationXML(station_network, \n",
    "                           station_name,\n",
    "                           station_lat, \n",
    "                           station_lon, \n",
    "                           station_depth, \n",
    "                           'enz')\n",
    "\n",
    "#         print(\"now syn sac \"+station_network+'_'+station_name+':\\n')\n",
    "\n",
    "        Add_waveforms([stream], \n",
    "                      catalog_create,\n",
    "                      Output_file_path,\n",
    "                      source_name,\n",
    "                      tp,\n",
    "                      ts,\n",
    "                      station_distance,\n",
    "                      station_az,\n",
    "                      station_baz) \n",
    "\n",
    "        Add_stationxml(inv,\n",
    "                       Output_file_path) \n",
    "\n",
    "        for j in range(0,3,1): \n",
    "            CHN = stream[j].stats.channel\n",
    "            sac_filename = os.path.join(Output_path,source_name+'.'+station_network+'.'+station_name+'.'+CHN+'.sac')\n",
    "            stream[j].write(sac_filename, format='SAC')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-[Turn back!](#helper_back)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}